{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit NNs with/without Dropout to pure noise and inspect what they have learned.\n",
    "We see that higher levels of Dropout preventing fitting to spurious high-order interaction effects.\n",
    "\n",
    "Reproduces Figures 5 and C1 in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Model, layers\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from purify import purify_3d\n",
    "from xgboost import XGBRegressor as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1000\n",
    "n_features = 25\n",
    "\n",
    "X = np.random.uniform(-1, 1., size=(n_samples, n_features)).astype(np.float32)\n",
    "Y = np.random.normal(0, 5., size=(n_samples, )).astype(np.float32)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_square(y_pred, y_true):\n",
    "    return tf.reduce_sum(tf.pow(y_pred-y_true, 2)) / (2 * n_samples)\n",
    "\n",
    "def run_optimization(model, variables, optimizer):\n",
    "    if variables is None:\n",
    "        variables = model.trainable_variables\n",
    "    with tf.GradientTape() as g:\n",
    "        pred = model(X_train, training=True)\n",
    "        loss = mean_square(pred, Y_train)\n",
    "        gradients = g.gradient(loss, variables)\n",
    "        optimizer.apply_gradients(zip(gradients, variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, variables, optimizer,\n",
    "          X_train, X_test, Y_train, Y_test,\n",
    "          training_steps=10000, display_steps=50):\n",
    "    prev_loss = np.inf\n",
    "    for step in range(0, training_steps + 1):\n",
    "        run_optimization(model, variables, optimizer)\n",
    "        loss = mean_square(model(X_train, training=False), Y_train)\n",
    "        if loss > prev_loss:\n",
    "            return\n",
    "        else:\n",
    "            prev_loss = loss\n",
    "        if step % display_steps == 0:\n",
    "            loss = mean_square(model(X_train, training=False), Y_train)\n",
    "            test_loss = mean_square(model(X_test, training=False), Y_test)\n",
    "            print(\"Step: {:d}, loss: {:.5f}, test loss {:.5f}\".format(step, loss, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(Model):\n",
    "    # Set layers.\n",
    "    def __init__(self, dropout_p, weight_decay, n_hidden_1, n_hidden_2, n_hidden_3,\n",
    "                 activation_dropout, input_dropout):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_dropout = input_dropout    \n",
    "        self.activation_dropout = activation_dropout\n",
    "        # First fully-connected hidden layer.\n",
    "        self.d0 = layers.Dropout(dropout_p)\n",
    "        self.fc1 = layers.Dense(n_hidden_1, activation=tf.nn.relu,\n",
    "                                kernel_initializer='glorot_uniform',\n",
    "                                bias_initializer='zeros')\n",
    "        self.d1 = layers.Dropout(dropout_p)\n",
    "        self.fc2 = layers.Dense(n_hidden_2, activation=tf.nn.relu,#.nn.relu,\n",
    "                                kernel_initializer='glorot_uniform',\n",
    "                                bias_initializer='zeros')\n",
    "        self.d2 = layers.Dropout(dropout_p)\n",
    "        self.fc3 = layers.Dense(n_hidden_3, activation=tf.nn.relu,\n",
    "                               kernel_initializer='glorot_uniform',\n",
    "                               bias_initializer='zeros')\n",
    "        self.d3 = layers.Dropout(dropout_p)\n",
    "        self.out = layers.Dense(1, activation=tf.identity,\n",
    "                                kernel_initializer='glorot_uniform',\n",
    "                                bias_initializer='zeros')\n",
    "\n",
    "    # Set forward pass.\n",
    "    def call(self, x, training):\n",
    "        if self.input_dropout:\n",
    "            x0 = self.d0(x, training=training)\n",
    "        else:\n",
    "            x0 = x\n",
    "        if self.activation_dropout:\n",
    "            output = self.out(\n",
    "                    self.d3(self.fc3(\n",
    "                        self.d2(self.fc2(\n",
    "                    self.d1(self.fc1(x0), training=training)),\n",
    "                                training=training)),\n",
    "                            training=training))\n",
    "        else:\n",
    "            output = self.out(self.fc3(\n",
    "                self.fc2(self.fc1(x0))))\n",
    "        return tf.squeeze(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def append_or_new(dictionary, key, entry):\n",
    "    try:\n",
    "        dictionary[key].append(entry)\n",
    "    except KeyError:\n",
    "        dictionary[key] = [entry]\n",
    "\n",
    "for n_hidden in [32]:#, 128]:\n",
    "    for input_dropout in [True]:\n",
    "        for activation_dropout in [True]:\n",
    "            if activation_dropout == False and input_dropout == False:\n",
    "                continue\n",
    "            print(activation_dropout, input_dropout)\n",
    "            n_fit_iters = 0\n",
    "            n_hidden_1 = n_hidden\n",
    "            n_hidden_2 = n_hidden\n",
    "            n_hidden_3 = n_hidden\n",
    "            dropout_ps = [0.0, 0.125, 0.25, 0.375, 0.5, 0.625, 0.75]\n",
    "            for fit_iter in range(n_fit_iters):\n",
    "                for dropout_p in dropout_ps:\n",
    "                    for weight_decay in [0.0]:\n",
    "                        print(dropout_p)\n",
    "                        # Build a new model.\n",
    "                        model = NeuralNet(dropout_p, weight_decay, n_hidden_1, n_hidden_2, n_hidden_3,\n",
    "                                          activation_dropout, input_dropout)\n",
    "                        optimizer = tf.optimizers.Adam(1e-3)\n",
    "\n",
    "                        # Fit the model.\n",
    "                        train(model, None, optimizer, \n",
    "                             X_train, X_test, Y_train, Y_test,\n",
    "                             training_steps=10000, display_steps=100)\n",
    "\n",
    "                        try:\n",
    "                            models[dropout_p].append(model)\n",
    "                        except KeyError:\n",
    "                            models[dropout_p] = [model]\n",
    "\n",
    "                        fig = plt.figure()\n",
    "                        plt.hist(model(X_train, training=False))\n",
    "                        plt.show()\n",
    "\n",
    "            # Decompose the models.\n",
    "            main_variances = {}\n",
    "            pair_variances = {}\n",
    "            three_variances = {}\n",
    "            four_variances = {}\n",
    "            good_dropout_ps = sorted(models.keys())\n",
    "            for dropout_p in good_dropout_ps:\n",
    "                for model in models[dropout_p]:\n",
    "                    print(dropout_p)\n",
    "                    pred = model(X, training=False).numpy()\n",
    "                    xgb1 = xgb(max_depth=1, n_estimators=1000)\n",
    "                    xgb2 = xgb(max_depth=2, n_estimators=1000)\n",
    "                    xgb3 = xgb(max_depth=3, n_estimators=1000)\n",
    "\n",
    "                    xgb1.fit(X, pred)\n",
    "                    xgb1_preds = xgb1.predict(X)\n",
    "\n",
    "                    xgb2.fit(X, pred)\n",
    "                    xgb2_preds = xgb2.predict(X)\n",
    "\n",
    "                    xgb3.fit(X, pred)\n",
    "                    xgb3_preds = xgb3.predict(X)\n",
    "                    residual3 = pred - xgb3_preds\n",
    "\n",
    "                    append_or_new(main_variances, dropout_p, np.var(xgb1_preds))\n",
    "                    append_or_new(pair_variances, dropout_p, np.var(xgb1_preds - xgb2_preds))\n",
    "                    append_or_new(three_variances, dropout_p, np.var(xgb2_preds - xgb3_preds))\n",
    "                    append_or_new(four_variances, dropout_p, np.var(residual3))\n",
    "\n",
    "\n",
    "            fig = plt.figure(figsize=(8, 8))\n",
    "            p0 = plt.errorbar(good_dropout_ps, np.array([np.mean(main_variances[p]) for p in good_dropout_ps]) / np.mean(main_variances[0]),\n",
    "                         yerr=np.array([np.std(main_variances[p])/np.mean(main_variances[0]) for p in good_dropout_ps]),\n",
    "                              label='$k=1$')\n",
    "            p1 = plt.errorbar(good_dropout_ps, np.array([np.mean(pair_variances[p]) for p in good_dropout_ps]) / np.mean(pair_variances[0]),\n",
    "                         yerr=np.array([np.std(pair_variances[p])/np.mean(pair_variances[0]) for p in good_dropout_ps]),\n",
    "                             label='$k=2$')\n",
    "            p2 = plt.errorbar(good_dropout_ps, np.array([np.mean(three_variances[p]) for p in good_dropout_ps]) / np.mean(three_variances[0]),\n",
    "                         yerr=np.array([np.std(three_variances[p])/np.mean(three_variances[0]) for p in good_dropout_ps]),\n",
    "                             label='$k=3$')\n",
    "            p3 = plt.errorbar(good_dropout_ps, np.array([np.mean(four_variances[p]) for p in good_dropout_ps]) / np.mean(four_variances[0]),\n",
    "                         yerr=np.array([np.std(four_variances[p])/np.mean(four_variances[0]) for p in good_dropout_ps]),\n",
    "                             label='$k\\geq 4$')\n",
    "\n",
    "            plt.legend(fontsize=26)\n",
    "            plt.xlabel('Dropout Rate', fontsize=32)\n",
    "            plt.ylabel('Normalized Effect Size', fontsize=32)\n",
    "            plt.xticks(fontsize=24)\n",
    "            plt.yticks(fontsize=24)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('results/intro_fig_decay_{}_{}_{}.pdf'.format(n_hidden_1, activation_dropout, input_dropout),\n",
    "                        bbox_inches='tight', dpi=300)\n",
    "\n",
    "            fig = plt.figure(figsize=(8, 8))\n",
    "            p0 = plt.bar(list(range(len(good_dropout_ps))), np.array([np.mean(main_variances[p]) for p in good_dropout_ps]),\n",
    "                        yerr=np.array([np.std(main_variances[p]) for p in good_dropout_ps]))\n",
    "            p1 = plt.bar(list(range(len(good_dropout_ps))), np.array([np.mean(pair_variances[p]) for p in good_dropout_ps]),\n",
    "                   bottom=np.array([np.mean(main_variances[p]) for p in good_dropout_ps]),\n",
    "                        yerr=np.array([np.std(pair_variances[p]) for p in good_dropout_ps]))\n",
    "            p2 = plt.bar(list(range(len(good_dropout_ps))), np.array([np.mean(three_variances[p]) for p in good_dropout_ps]),\n",
    "                   bottom=np.array([np.mean(main_variances[p]) for p in good_dropout_ps])\n",
    "                         + np.array([np.mean(pair_variances[p]) for p in good_dropout_ps]),\n",
    "                        yerr=np.array([np.std(three_variances[p]) for p in good_dropout_ps]))\n",
    "            p3 = plt.bar(list(range(len(good_dropout_ps))), np.array([np.mean(four_variances[p]) for p in good_dropout_ps]),\n",
    "                   bottom=np.array([np.mean(main_variances[p]) for p in good_dropout_ps])\n",
    "                         + np.array([np.mean(pair_variances[p]) for p in good_dropout_ps])\n",
    "                         + np.array([np.mean(three_variances[p]) for p in good_dropout_ps]),\n",
    "                        yerr=np.array([np.std(four_variances[p]) for p in good_dropout_ps]))\n",
    "\n",
    "            plt.xlabel(\"Dropout Rate\", fontsize=32)\n",
    "            plt.ylabel(\"Effect Size\", fontsize=32)\n",
    "            plt.xticks([i for i in range(len(dropout_ps))], dropout_ps, fontsize=24)\n",
    "            plt.yticks(fontsize=24)\n",
    "            plt.legend((p0[0], p1[0], p2[0], p3[0]), ('$k=1$', '$k=2$', '$k=3$', '$k\\geq 4$'), fontsize=26)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('results/intro_fig_total_{}_{}_{}.pdf'.format(n_hidden_1, activation_dropout, input_dropout),\n",
    "                        dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "\n",
    "            fig = plt.figure(figsize=(8, 8))\n",
    "            total_variances = {p : np.array(main_variances[p]) + np.array(pair_variances[p]) + np.array(three_variances[p]) + np.array(four_variances[p]) for p in good_dropout_ps}\n",
    "            main_variances_normed = {p: (total_variances[p] > 2e-2)*main_variances[p] / total_variances[p] for p in good_dropout_ps}\n",
    "            pair_variances_normed = {p: (total_variances[p] > 2e-2)*pair_variances[p] / total_variances[p] for p in good_dropout_ps}\n",
    "            three_variances_normed = {p: (total_variances[p] > 2e-2)*three_variances[p] / total_variances[p] for p in good_dropout_ps}\n",
    "            four_variances_normed = {p: (total_variances[p] > 2e-2)*four_variances[p] / total_variances[p] for p in good_dropout_ps}\n",
    "            p0 = plt.bar(list(range(len(good_dropout_ps))), np.array([np.mean(main_variances_normed[p]) for p in good_dropout_ps]),\n",
    "                        yerr=np.array([np.std(main_variances_normed[p]) for p in good_dropout_ps]))\n",
    "            p1 = plt.bar(list(range(len(good_dropout_ps))), np.array([np.mean(pair_variances_normed[p]) for p in good_dropout_ps]),\n",
    "                   bottom=np.array([np.mean(main_variances_normed[p]) for p in good_dropout_ps]),\n",
    "                        yerr=np.array([np.std(pair_variances_normed[p]) for p in good_dropout_ps]))\n",
    "            p2 = plt.bar(list(range(len(good_dropout_ps))), np.array([np.mean(three_variances_normed[p]) for p in good_dropout_ps]),\n",
    "                   bottom=np.array([np.mean(main_variances_normed[p]) for p in good_dropout_ps])\n",
    "                         + np.array([np.mean(pair_variances_normed[p]) for p in good_dropout_ps]),\n",
    "                        yerr=np.array([np.std(three_variances_normed[p]) for p in good_dropout_ps]))\n",
    "            p3 = plt.bar(list(range(len(good_dropout_ps))), np.array([np.mean(four_variances_normed[p]) for p in good_dropout_ps]),\n",
    "                   bottom=np.array([np.mean(main_variances_normed[p]) for p in good_dropout_ps])\n",
    "                         + np.array([np.mean(pair_variances_normed[p]) for p in good_dropout_ps])\n",
    "                         + np.array([np.mean(three_variances_normed[p]) for p in good_dropout_ps]),\n",
    "                        yerr=np.array([np.std(four_variances_normed[p]) for p in good_dropout_ps]))\n",
    "\n",
    "            plt.xlabel(\"Dropout Rate\", fontsize=32)\n",
    "            plt.ylabel(\"Normalized Effect Size\", fontsize=32)\n",
    "            plt.xticks([i for i in range(len(good_dropout_ps))], good_dropout_ps, fontsize=24)\n",
    "            plt.yticks(fontsize=24)\n",
    "            plt.legend((p0[0], p1[0], p2[0], p3[0]), ('$k=1$', '$k=2$', '$k=3$', '$k\\geq 4$'), fontsize=26)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('results/fixed_intro_fig_normed_{}_{}_{}.pdf'.format(n_hidden_1, activation_dropout, input_dropout),\n",
    "                        bbox_inches='tight', dpi=300)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "p0 = plt.errorbar(good_dropout_ps, np.array([np.mean(main_variances[p]) for p in good_dropout_ps]) / np.mean(main_variances[0]),\n",
    "             yerr=np.array([np.std(main_variances[p])/np.mean(main_variances[0]) for p in good_dropout_ps]),\n",
    "                  label='$k=1$')\n",
    "p1 = plt.errorbar(good_dropout_ps, np.array([np.mean(pair_variances[p]) for p in good_dropout_ps]) / np.mean(pair_variances[0]),\n",
    "             yerr=np.array([np.std(pair_variances[p])/np.mean(pair_variances[0]) for p in good_dropout_ps]),\n",
    "                 label='$k=2$')\n",
    "p2 = plt.errorbar(good_dropout_ps, np.array([np.mean(three_variances[p]) for p in good_dropout_ps]) / np.mean(three_variances[0]),\n",
    "             yerr=np.array([np.std(three_variances[p])/np.mean(three_variances[0]) for p in good_dropout_ps]),\n",
    "                 label='$k=3$')\n",
    "p3 = plt.errorbar(good_dropout_ps, np.array([np.mean(four_variances[p]) for p in good_dropout_ps]) / np.mean(four_variances[0]),\n",
    "             yerr=np.array([np.std(four_variances[p])/np.mean(four_variances[0]) for p in good_dropout_ps]),\n",
    "                 label='$k\\geq 4$')\n",
    "\n",
    "plt.legend(fontsize=26)\n",
    "plt.xlabel('Dropout Rate', fontsize=32)\n",
    "plt.ylabel('Normalized Effect Size', fontsize=32)\n",
    "plt.xticks(fontsize=24)\n",
    "plt.yticks(fontsize=24)\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/intro_fig_decay_{}_{}_{}.pdf'.format(n_hidden_1, activation_dropout, input_dropout),\n",
    "            bbox_inches='tight', dpi=300)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "p0 = plt.bar(list(range(len(good_dropout_ps))), np.array([np.mean(main_variances[p]) for p in good_dropout_ps]),\n",
    "            yerr=np.array([np.std(main_variances[p]) for p in good_dropout_ps]))\n",
    "p1 = plt.bar(list(range(len(good_dropout_ps))), np.array([np.mean(pair_variances[p]) for p in good_dropout_ps]),\n",
    "       bottom=np.array([np.mean(main_variances[p]) for p in good_dropout_ps]),\n",
    "            yerr=np.array([np.std(pair_variances[p]) for p in good_dropout_ps]))\n",
    "p2 = plt.bar(list(range(len(good_dropout_ps))), np.array([np.mean(three_variances[p]) for p in good_dropout_ps]),\n",
    "       bottom=np.array([np.mean(main_variances[p]) for p in good_dropout_ps])\n",
    "             + np.array([np.mean(pair_variances[p]) for p in good_dropout_ps]),\n",
    "            yerr=np.array([np.std(three_variances[p]) for p in good_dropout_ps]))\n",
    "p3 = plt.bar(list(range(len(good_dropout_ps))), np.array([np.mean(four_variances[p]) for p in good_dropout_ps]),\n",
    "       bottom=np.array([np.mean(main_variances[p]) for p in good_dropout_ps])\n",
    "             + np.array([np.mean(pair_variances[p]) for p in good_dropout_ps])\n",
    "             + np.array([np.mean(three_variances[p]) for p in good_dropout_ps]),\n",
    "            yerr=np.array([np.std(four_variances[p]) for p in good_dropout_ps]))\n",
    "\n",
    "plt.xlabel(\"Dropout Rate\", fontsize=32)\n",
    "plt.ylabel(\"Effect Size\", fontsize=32)\n",
    "plt.xticks([i for i in range(len(dropout_ps))], dropout_ps, fontsize=24)\n",
    "plt.yticks(fontsize=24)\n",
    "plt.legend((p0[0], p1[0], p2[0], p3[0]), ('$k=1$', '$k=2$', '$k=3$', '$k\\geq 4$'), fontsize=26)\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/intro_fig_total_{}_{}_{}.pdf'.format(n_hidden_1, activation_dropout, input_dropout),\n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "total_variances = {p : np.array(main_variances[p]) + np.array(pair_variances[p]) + np.array(three_variances[p]) + np.array(four_variances[p]) for p in good_dropout_ps}\n",
    "main_variances_normed = {p: np.array(main_variances[p]) / total_variances[p] for p in good_dropout_ps}\n",
    "pair_variances_normed = {p: pair_variances[p] / total_variances[p] for p in good_dropout_ps}\n",
    "three_variances_normed = {p: three_variances[p] / total_variances[p] for p in good_dropout_ps}\n",
    "four_variances_normed = {p: four_variances[p] / total_variances[p] for p in good_dropout_ps}\n",
    "p0 = plt.bar(list(range(len(good_dropout_ps))), np.array([np.mean(main_variances_normed[p]) for p in good_dropout_ps]),\n",
    "            yerr=np.array([np.std(main_variances_normed[p]) for p in good_dropout_ps]))\n",
    "p1 = plt.bar(list(range(len(good_dropout_ps))), np.array([np.mean(pair_variances_normed[p]) for p in good_dropout_ps]),\n",
    "       bottom=np.array([np.mean(main_variances_normed[p]) for p in good_dropout_ps]),\n",
    "            yerr=np.array([np.std(pair_variances_normed[p]) for p in good_dropout_ps]))\n",
    "p2 = plt.bar(list(range(len(good_dropout_ps))), np.array([np.mean(three_variances_normed[p]) for p in good_dropout_ps]),\n",
    "       bottom=np.array([np.mean(main_variances_normed[p]) for p in good_dropout_ps])\n",
    "             + np.array([np.mean(pair_variances_normed[p]) for p in good_dropout_ps]),\n",
    "            yerr=np.array([np.std(three_variances_normed[p]) for p in good_dropout_ps]))\n",
    "p3 = plt.bar(list(range(len(good_dropout_ps))), np.array([np.mean(four_variances_normed[p]) for p in good_dropout_ps]),\n",
    "       bottom=np.array([np.mean(main_variances_normed[p]) for p in good_dropout_ps])\n",
    "             + np.array([np.mean(pair_variances_normed[p]) for p in good_dropout_ps])\n",
    "             + np.array([np.mean(three_variances_normed[p]) for p in good_dropout_ps]),\n",
    "            yerr=np.array([np.std(four_variances_normed[p]) for p in good_dropout_ps]))\n",
    "\n",
    "plt.xlabel(\"Dropout Rate\", fontsize=32)\n",
    "plt.ylabel(\"Normalized Effect Size\", fontsize=32)\n",
    "plt.xticks([i for i in range(len(good_dropout_ps))], good_dropout_ps, fontsize=24)\n",
    "plt.yticks(fontsize=24)\n",
    "plt.legend((p0[0], p1[0], p2[0], p3[0]), ('$k=1$', '$k=2$', '$k=3$', '$k\\geq 4$'), fontsize=26)\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/intro_fig_normed_{}_{}_{}.pdf'.format(n_hidden_1, activation_dropout, input_dropout),\n",
    "            bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
